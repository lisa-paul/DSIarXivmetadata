<h1 align = 'center'>arXiv Unveiled: Analyzing Metadata on Scientific Papers</h1>

<h4 align = 'center'>GA DSI-911 Capstone</h4>
<center> Lisa Paul</center>

 <br><hr><br>


## Problem Statement
>For this preliminary study, we asked "Can we predict which research field the article is in, based on its abstract alone?"

## Executive Summary
>	The Data Analyst Think Tank is a cutting-edge research consortium dedicated to advancing scientific insights through rigorous data analysis. Focused on unraveling the complexities of research articles stored at ArXiv, our team employs state-of-the-art analytical methods to extract valuable patterns and trends, contributing to the evolution of scientific knowledge. As the forefront of data-driven research, we aim to bridge gaps in understanding and propel innovation within the scientific community.

>	- "This autogenerated mission statement encapsulates the core of our mission."

> We hope this study can lead to better streamlining of categorization and retrieval of scientific knowledge: affording quicker access to relevant information. Successful predictions and auto-categorization can enhance the efficiency of literature reviews, provide reading recommendations for scientists, and suggest publication venues or conferences that a given article may be useful towards.


## What is arXiv?
> arXiv.org is a free-to-access preprint repository that hosts scholarly articles in various fields of science and mathematics. It allows researchers to share their work with the global scientific community before formal peer review and publication, promoting open access and collaboration.

 <br><hr><br>
## File Directory / Table of Contents
This is an alphabetical list of the repository's directory and file structure. 
```
├── README.md
├── code
│   ├── 00-json-to-csv.ipynb
│   └── 01-preprocess-EDA.ipynb
├── data
│   ├── arxiv_meta_aa-single-cat.csv
│   ├── arxiv_meta_bb-single-cat.csv
│   ├── featured.csv
│   ├── features.csv
│   └── target.csv
├── images
│   └── top_categories_plot.png
├── presentation
│   └── Lisa Paul GA DSI Capstone_ arXiv metadata.pdf
```


<br><hr><br>
## Software Requirements
- Jupyter Notebook
- Matplotlib.pyplot
- NLTK
- NumPy
- Pandas
- Scikit-Learn (sklearn)
- Seaborn




<br><hr><br>
## Data Dictionary
> My source dataset via Kaggle is a mirror of the original arXiv data. Because the full dataset is rather large (1.1TB and growing), this dataset provides only a metadata file in the json format. This file contains an entry for each paper, containing:

| Feature        | Description                                     |
| -------------- | ----------------------------------------------- |
| id             | ArXiv ID (can be used to access the paper)      |
| submitter      | Who submitted the paper                         |
| authors        | Authors of the paper                             |
| title          | Title of the paper                               |
| comments       | Additional info, such as number of pages and figures |
| journal-ref    | Information about the journal the paper was published in |
| doi            | [Digital Object Identifier](https://www.doi.org) |
| abstract       | The abstract of the paper                        |
| categories     | Categories / tags in the ArXiv system            |
| versions       | A version history                                |


<br><hr><br>
## Methods
** baseline/benchmark prediction:**  the "most common" class
> Preliminary study design is very simple:
	- Pipelining a simple CountVectorizer, plus one basic (Multinomial Naive Bayes) model, into a GridSearch
> These simple preliminary Models, may give a fast/intuitive answer for clients

- Evaluation metrics and criteria
> We focus on fundamental metrics like accuracy, precision, recall, and F1 score. As we progress to our pipeline/GridSearch models, these metrics will remain crucial, with additional emphasis on fine-tuning hyperparameters to optimize performance and achieve the best predictive outcomes.

<br><hr><br>
## Conclusions and Recommendations

> Current baseline prediction accuracy is approximately 26%, reflecting the inherent imbalance in the original dataset, but this accuracy may vary across different data chunks and cannot be guaranteed for future research imports.

> Additionally, the NLP model, in its current state, did not yield useful results. 

> Next Steps before Project Expansion:
  1. need to fix code errors
  2. Recommend grouping categories into "most common ten" vs "other", to binarize the prediction in order to speed up results

<br><hr><br>
## Sources
- [arXiv Dataset](https://www.kaggle.com/dsv/7053634)
- [Split JSON into multiple files](https://stackoverflow.com/a/44216101)
- 
